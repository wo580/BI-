{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action2\t\"汽车投诉信息采集：\n",
    "数据源：http://www.12365auto.com/zlts/0-0-0-0-0-0_0-0-1.shtml\n",
    "投诉编号，投诉品牌，投诉车系，投诉车型，问题简述，典型问题，投诉时间，投诉状态\n",
    "可以采用Python爬虫，或者第三方可视化工具\"\t\t\t\n",
    "1、完成代码（20points）\n",
    "2、结果正确（20points）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用request + BeautifulSoup提取12365auto投诉信息\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os    #获取当前工作路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#请求URL\n",
    "#request_url = 'http://www.12365auto.com/zlts/0-0-0-0-0-0_0-0-1.shtml'\n",
    "# 根据request_url得到soup\n",
    "def get_page_content(request_url):\n",
    "    # 得到页面的内容\n",
    "    headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'}\n",
    "    html=requests.get(request_url,headers=headers,timeout=10)\n",
    "    content = html.text\n",
    "     # 通过content创建BeautifulSoup对象\n",
    "    soup = BeautifulSoup(content, 'html.parser', from_encoding='utf-8')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过BS对象来提取当前页面的内容（方法一）\n",
    "def analysis(soup):\n",
    "    #找出投诉框\n",
    "    temp=soup.find('div',class_='tslb_b')\n",
    "    #投诉编号\t投诉品牌\t投诉车系\t投诉车型\t问题简述\t典型问题\t投诉时间\t投诉状态\n",
    "    df=pandas.DataFrame(columns=['id_','brand','car_model','type_','desc','problem','datetime','status'])#定义一个空的df\n",
    "    tr_list=temp.find_all('tr')\n",
    "    for tr in tr_list:\n",
    "        td_list=tr.find_all('td')\n",
    "        df_tr=pd.DataFrame()\n",
    "        if len(td_list)>0:\n",
    "            df_tr = df_tr.assign(\n",
    "                id_=[td_list[0].text],\n",
    "                brand=[td_list[1].text],\n",
    "                car_model=[td_list[2].text],\n",
    "                type_=[td_list[3].text],\n",
    "                desc=[td_list[4].text],\n",
    "                problem=[td_list[5].text],\n",
    "                datetime=[td_list[6].text],\n",
    "                status =[td_list[7].text]\n",
    "            )\n",
    "            df=pd.concat([df,df_tr],axis=0,ignore_index=True)\n",
    "    return df \n",
    "\n",
    "request_url = 'http://www.12365auto.com/zlts/0-0-0-0-0-0_0-0-1.shtml'\n",
    "bs = get_page_content(request_url)\n",
    "df =analysis(bs) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过BS对象来提取当前页面的内容（方法二）\n",
    "def analysis(soup):\n",
    "    #找出投诉框\n",
    "    temp=soup.find('div',class_='tslb_b')\n",
    "    #投诉编号\t投诉品牌\t投诉车系\t投诉车型\t问题简述\t典型问题\t投诉时间\t投诉状态\n",
    "    df=pandas.DataFrame(columns=['id','brand','car_model','type','desc','problem','datetime','status'])#定义一个空的df\n",
    "    tr_list=temp.find_all('tr')\n",
    "    for tr in tr_list:\n",
    "        temp={}\n",
    "        td_list=tr.find_all('td')\n",
    "        #第一个TR没有td,其余八个都有\n",
    "        for td in td_list:\n",
    "            if len(td_list) > 0:\n",
    "                id,brand,car_model,type,desc,problem,datetime,status = \\\n",
    "                td_list[0].text,td_list[1].text,td_list[2].text,td_list[3].text,td_list[4].text, \\\n",
    "                td_list[5].text,td_list[6].text,td_list[7].text\n",
    "                \n",
    "                temp['id'],temp['brand'],temp['car_model'],temp['type'],temp['desc'],temp['problem'], \\\n",
    "                temp['datetime'],temp['status'] = \\\n",
    "                id,brand,car_model,type,desc,problem,datetime,status\n",
    "                \n",
    "                df = df.append(temp, ignore_index=True)\n",
    "    return df \n",
    "\n",
    "request_url = 'http://www.12365auto.com/zlts/0-0-0-0-0-0_0-0-1.shtml'\n",
    "bs = get_page_content(request_url)\n",
    "df =analysis(bs) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_num = 20\n",
    "base_url = 'http://www.12365auto.com/zlts/0-0-0-0-0-0_0-0-0-0-0-0-0-'\n",
    "\n",
    "result = pd.DataFrame(columns = ['id', 'brand', 'car_model', 'type', 'desc', 'problem', 'datetime', 'status'])\n",
    "for i in range(page_num):\n",
    "    request_url = base_url+str(i+1)+'.shtml'\n",
    "    soup = get_page_content(request_url)\n",
    "    print(request_url)\n",
    "    df = analysis(soup)\n",
    "    print(df)\n",
    "    result = result.append(df)\n",
    "result.to_csv(r'C:\\Users\\Administrator\\BI\\calss1-2\\car_complain.csv', index=False,encoding=\"utf_8_sig\") #数据写入，index=False表示不加索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
