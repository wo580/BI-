{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action1\t\"文本抄袭自动检测分析:\n",
    "如果你是某新闻单位工作人员（这里假设source=新华社），为了防止其他媒体抄袭你的文章，你打算做一个抄袭自动检测分析的工具\n",
    "1）定义可能抄袭的文章来源\n",
    "2）与原文对比定位抄袭的地方\n",
    "原始数据：sqlResult.csv，共计89611篇\n",
    "从数据库导出的文章，字段包括：id, author, source, content, feature, title, url\n",
    "常用中文停用词：chinese_stopwords.txt\"\t\t\t\t\"\n",
    "1、完成聚类算法（10points）\n",
    "2、完成分类算法（10points）\n",
    "3、完成相似度计算，Top-N排序（10points）\n",
    "4、完成代码，结果正确（30points）\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本抄袭自动检测：\n",
    "Step1，数据加载\n",
    "加载sqlResult.csv及停用词chinese_stopwords.txt\n",
    "Step2，数据预处理\n",
    "1）数据清洗，针对content字段为空的情况，进行dropna\n",
    "2）分词，使用jieba进行分词\n",
    "3）将处理好的分词保存到 corpus.pkl，方便下次调用\n",
    "4）数据集切分，70%训练集，30%测试集\n",
    "Step3，提取文本特征TF-IDF\n",
    "Step4，预测文章风格是否和自己一致\n",
    "使用分类模型（比如MultinomialNB），对于文本的特征（比如TF-IDF）和label（是否为新华社）进行训练\n",
    "Step5，找到可能Copy的文章，即预测label=1，但实际label=0\n",
    "Step6，根据模型预测的结果来对全量文本进行比对，如果数量很大，我们可以先用k-means进行聚类降维，比如k=25种聚类\n",
    "Step7，找到一篇可能的Copy文章，从相同label中，找到对应新华社的文章，并按照TF-IDF相似度矩阵，从大到小排序，取Top10\n",
    "Step8，使用编辑距离editdistance，计算两篇文章的距离\n",
    "Step9，精细比对，对于疑似文章与原文进行逐句比对，即计算每个句子的编辑距离editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载\n",
    "news = pd.read_csv('sqlResult.csv',encoding='gb18030')\n",
    "print(news.shape)\n",
    "print(news.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news[news.content.isna()].head()\n",
    "news = news.dropna(subset = ['content'])\n",
    "print(news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载停用词\n",
    "with open('chinese_stopwords.txt','r',encoding = 'utf-8') as file:\n",
    "    stopwords = [i[:-1] for i in file.readlines()]\n",
    "    \n",
    "\n",
    "#分词\n",
    "def split_text(text):\n",
    "    text  = text.replace(' ','').replace('\\n','')\n",
    "    text2 = jieba.cut(text)\n",
    "    result = ' '.join([w for w in text2 if w not in stopwords])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news.iloc[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text(news.iloc[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(map(split_text,[str(i) for i in news.content]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "#计算corpus的TFIDF（文本特征）\n",
    "countvectorizer = CountVectorizer(encoding = 'gb18030', min_df = 0.015)\n",
    "tfidftransformer = TfidfTransformer()\n",
    "\n",
    "countvector = countvectorizer.fit_transform(corpus)\n",
    "tfidf = tfidftransformer.fit_transform(countvector)\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标记是否为自己的新闻\n",
    "label = list(map(lambda source:1 if '新华社' in str(source) else 0,news.source))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#切分数据集\n",
    "x_train,x_test,y_train,y_test = train_test_split(tfidf.toarray(),label,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "model2 = BernoulliNB()\n",
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8802695562277444\n",
      "精确度： 0.961746906331858\n",
      "召回率： 0.903287380699894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "print('准确率：',accuracy_score(y_test,y_predict))\n",
    "print('精确度：',precision_score(y_test,y_predict))\n",
    "print('召回率：',recall_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8245204273078838\n",
      "精确度： 0.9660384766391834\n",
      "召回率： 0.8349522799575821\n"
     ]
    }
   ],
   "source": [
    "y2_predict = model2.predict(x_test)\n",
    "print('准确率：',accuracy_score(y_test,y2_predict))\n",
    "print('精确度：',precision_score(y_test,y2_predict))\n",
    "print('召回率：',recall_score(y_test,y2_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用模型进行风格预测\n",
    "prediction = model.predict(tfidf.toarray())\n",
    "labels = np.array(label)\n",
    "\n",
    "#prediction为预测风格，labels为真实结果\n",
    "compare_news_index = pd.DataFrame({'prediction':prediction,'labels':labels})\n",
    "copy_news_index = compare_news_index[(compare_news_index['prediction'] == 1) & (compare_news_index['labels'] == 0)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计实际为新华社的新闻\n",
    "xhs_news_index = compare_news_index[(compare_news_index['labels'] == 1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可能为抄袭的新闻条数： 2794\n"
     ]
    }
   ],
   "source": [
    "print('可能为抄袭的新闻条数：',len(copy_news_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87054,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "normalizer = Normalizer()\n",
    "scaled_array = normalizer.fit_transform(tfidf.toarray())\n",
    "\n",
    "#使用Kmeans进行全量文档进行聚类\n",
    "kmeans = KMeans(n_clusters = 25)\n",
    "k_labels = kmeans.fit_predict(scaled_array)\n",
    "print(k_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建id_class,ID(1-8700+),class(1-25)索引\n",
    "id_class = {index:class_ for index, class_ in enumerate(k_labels)}\n",
    "from collections import defaultdict\n",
    "class_id = defaultdict(set)\n",
    "\n",
    "for index,class_ in id_class.items():\n",
    "    #只统计新华社发布的class_id\n",
    "    if index in xhs_news_index.tolist():\n",
    "        class_id[class_].add(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#查找相似文章\n",
    "def find_similar_text(cpindex,top=10):\n",
    "    #只在新华社发布得的文章找\n",
    "    dist_dist = {i:cosine_similarity(tfidf[cpindex],tfidf[i])for i in class_id[id_class[cpindex]]}\n",
    "    #从大到小排序\n",
    "    return sorted(dist_dist.items(),key=lambda x:x[1][0],reverse =True)[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否在新华社 False\n",
      "是否在抄袭新闻里 True\n"
     ]
    }
   ],
   "source": [
    "cpindex = 3352\n",
    "print('是否在新华社',cpindex in xhs_news_index)\n",
    "print('是否在抄袭新闻里',cpindex in copy_news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3134, array([[0.96849134]])), (63511, array([[0.94643198]])), (29441, array([[0.94283416]])), (3218, array([[0.87621892]])), (29615, array([[0.86936328]])), (29888, array([[0.86215862]])), (64046, array([[0.85278235]])), (29777, array([[0.84875422]])), (63974, array([[0.73415212]])), (63975, array([[0.73415212]]))]\n"
     ]
    }
   ],
   "source": [
    "similar_list = find_similar_text(cpindex)\n",
    "print(similar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "怀疑抄袭：\n",
      " 　　中国5月份56座城市新建商品住宅价格环比上涨，4月份为58座上涨。5月份15个一线和热点二线城市房地产市场基本稳定，5月份房地产调控政策效果继续显现。\n",
      "　　统计局：15个一线和热点二线城市房价同比涨幅全部回落\n",
      "　　国家统计局城市司高级统计师刘建伟解读5月份房价数据\n",
      "　　5月份一二线城市房价平均涨幅继续回落\n",
      "　　国家统计局今日发布了2017年5月份70个大中城市住宅销售价格统计数据。对此，国家统计局城市司高级统计师刘建伟进行了解读。\n",
      "　　一、15个一线和热点二线城市新建商品住宅价格同比涨幅全部回落、9个城市环比下降或持平\n",
      "　　5月份，因地制宜、因城施策的房地产调控政策效果继续显现，15个一线和热点二线城市房地产市场基本稳定。从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.5至6.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内。\n",
      "　　二、70个大中城市中一二线城市房价同比涨幅持续回落\n",
      "　　5月份，70个城市中新建商品住宅和二手住宅价格同比涨幅比上月回落的城市分别有29和18个。其中，一二线城市同比涨幅回落尤其明显。据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点。\n",
      "　　三、70个大中城市中房价环比下降及涨幅回落城市个数均有所增加\n",
      "　　5月份，70个城市中新建商品住宅价格环比下降的城市有9个，比上月增加1个；涨幅回落的城市有26个，比上月增加3个。二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个。\n",
      "\n",
      "相似的原文：\n",
      " 　　国家统计局19日发布数据，5月份，15个一线和热点二线城市新建商品住宅价格同比涨幅全部回落，其中9个城市环比下降或持平。这9个价格环比下降或持平的城市为：北京、上海、南京、杭州、合肥、福州、郑州、深圳、成都。\n",
      "　　“5月份，因地制宜、因城施策的房地产调控政策效果继续显现，15个一线和热点二线城市房地产市场基本稳定。”国家统计局城市司高级统计师刘建伟说，从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.5至6.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内。\n",
      "　　国家统计局当天还发布了5月份70个大中城市住宅销售价格统计数据。刘建伟介绍，5月份，70个大中城市中新建商品住宅和二手住宅价格同比涨幅比上月回落的城市分别有29和18个。其中，一二线城市同比涨幅回落尤其明显。据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点。\n",
      "　　此外，70个大中城市中房价环比下降及涨幅回落城市个数均有所增加。统计显示，5月份，70个大中城市中新建商品住宅价格环比下降的城市有9个，比上月增加1个；涨幅回落的城市有26个，比上月增加3个。二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('怀疑抄袭：\\n',news.iloc[cpindex].content)\n",
    "#找一篇相似的文章\n",
    "similar2 = similar_list[0][0]\n",
    "print('相似的原文：\\n',news.iloc[similar2].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
